from encodings import normalize_encoding
from locale import normalize
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import os
import time

# per variable
auc_scores_hand = {
    "sigJetRecur_dr12": [0.73],
    "sigJetRecur_z": [0.51],
    "sigJetRecur_jetpt": [0.49],
}

# per job per dimension TODO result for every trial for every hidden dim
auc_scores_lstm = {
    "22_08_09_1909": [[0.4608, 0.4606, 0.5236]],
    "22_08_09_1934": [[0.6078, 0.6223, 0.6018]],
    "22_08_09_1941": [[0.4816, 0.5774, 0.4019]],
    "22_08_11_1520": [[0.6820, 0.2809, 0.4418]],
    "10993304": [[0.3523,0.4577,0.5105]],
    "10993305": [[0.4364,0.3418,0.4589]],
    "11461549": [[0.7090, 0.5521, 0.5006], [0.5071,0.4753,0.5374], [0.4671,0.5409,0.5072], [0.5108,0.4905,0.5057], [0.4795,0.5698,0.4199],[0.7282,0.5021,0.4937], [0.5522,0.5451,0.5148], [0.4693,0.5165,0.4192], [0.6706,0.4500,0.5122],[0.5417,0.5265,0.4786]],
    "11461550": [[0.4793,0.7409,0.4813], [0.5344,0.4826,0.6915], [0.6060,0.4759,0.5005], [0.4257,0.4845,0.4330], [0.4479,0.4886,0.4508], [0.7081,0.5085,0.4710], [0.4860,0.5039,0.5700], [0.5131,0.5648,0.6011], [0.5587,0.4891,0.5186], [0.5011,0.3803,0.4546]],


}

# per job
auc_scores_lstm_ocsvm = {
    "22_07_18_1520": [0.62],
    "22_08_09_1909": [0.49],
    "22_08_09_1934": [0.35],
    "22_08_09_1941": [0.55],
    "22_08_11_1520": [0.42],
    '22_07_18_1327': [0.29389671361502345], 
    '22_07_18_1334': [0.29325920434890046], 
    '22_07_18_1340': [0.3298888065233507], 
    '22_07_18_1345': [0.28823820113664445], 
    '22_07_18_1357': [0.31957499382258464], 
    '22_07_18_1404': [0.42499135161848284], 
    '22_07_18_1410': [0.3892760069187052], 
    '22_07_18_1414': [0.3968173956016802], 
    '22_07_18_1417': [0.39421299728193726], 
    '22_07_18_1432': [0.4506597479614529], 
    '22_07_18_1435': [0.4375982209043736], 
    '22_07_18_1440': [0.4157499382258463], 
    '22_07_18_1445': [0.429424264887571], 
    '22_07_18_1452': [0.4341586360266865], 
    '22_07_18_1502': [0.4204348900420064], 
    '22_07_18_1508': [0.5465678280207561], 
    '22_07_18_1514': [0.4053471707437608], 
    '22_07_18_1520': [0.6199456387447492], 
    '22_08_09_1909': [0.4948356807511737], 
    '22_08_09_1934': [0.345910551025451], 
    '22_08_09_1941': [0.551830985915493], 
    '22_08_11_1520': [0.4168668149246355],
    '10993304': [0.5371237954040029], 
    '10993305': [0.4154583642204102], 
    '11461549': [0.5294183234988287, 0.4641886220418186, 0.4717029353177735, 0.5017614412247403, 0.36088748574936413, 0.38059909046491525, 0.4864421643427168, 0.47447288307588226, 0.6490961025294095, 0.44672454617206], 
    '11461550': [0.26229563648663884, 0.49908921211210083, 0.5101477054910362, 0.5034452086543642, 0.5527267260495359, 0.5011525788952782, 0.49296049911677375, 0.6587514563836585, 0.39557008807206123, 0.5253166459954147]
}

auc_scores_lstm_ocsvm_hypertraining = {
    '11120653': [0.45917963923894245,0.4075463306152706, 0.4293353101062516, 0.7475908080059303, 0.5191648134420559, 0.4802372127501854, 0.5278823820113664, 0.4630985915492958, 0.5128984432913269, 0.5687818136891525, 0.422070669631826, 0.4767185569557697, 0.5611020509019027, 0.568722510501606, 0.5421793921423276, 0.47654558932542623, 0.6796837163330862, 0.5386360266864344, 0.43516679021497406, 0.4681838398813936, 0.3796244131455399, 0.48982456140350883, 0.49778107239930813, 0.46797627872498154, 0.5056634544106746, 0.4827971336792685, 0.47819125277983693, 0.49321966889053614, 0.4925574499629355, 0.5137929330368174, 0.5310699283419817, 0.40343958487768716], 
    '11120654': [0.37694094390906846, 0.5210476896466518, 0.5840820360761058, 0.7074870274277242, 0.6996046454163578, 0.4804200642451198, 0.35522115147022487, 0.5476995305164319, 0.4595552260934025, 0.4822881146528292, 0.5241858166543119, 0.5198715097603163, 0.4416061279960465, 0.681077341240425, 0.4248035581912528, 0.3657721769211762, 0.5657029898690389, 0.4419273535952558, 0.48297010130961204, 0.4731554237706943, 0.43667407956511, 0.600439831974302, 0.5180380528786755, 0.46382011366444276, 0.49292809488510003, 0.4867062021250309, 0.4358537188040524, 0.47353595255744996, 0.6953990610328639, 0.4507437608104769, 0.4507832962688411, 0.6531208302446256, 0.6575537435137138, 0.6940696812453669, 0.5057227575982209, 0.3790511489992587, 0.4826735853718803, 0.45021003212255994, 0.45845317519149986, 0.4968964665184087, 0.37382752656288604, 0.4528440820360761, 0.4948455646157648, 0.36478379046207066, 0.5389424264887571], 
    '11120655': [0.4611069928341982, 0.4702100321225599, 0.33580429948109713, 0.5029157400543612, 0.44941932295527554, 0.5196837163330863, 0.37785025945144546, 0.512656288608846, 0.3178008401284902, 0.6990313812700766, 0.33499382258463056, 0.3587842846553002, 0.4800444773906597, 0.5011860637509266, 0.5011020509019026, 0.5540202619224117, 0.5435829009142575, 0.5127748949839387, 0.6644625648628614, 0.380721522115147, 0.5007165801828515, 0.5232863849765258, 0.39210279219174693, 0.34409686187299227, 0.5944403261675315, 0.4889696071163825, 0.5434890042006424, 0.36294539164813444, 0.46502594514455153, 0.3148307388188782, 0.4665085248332098, 0.3363627378304917, 0.5427674820854954, 0.503953545836422, 0.38967136150234744, 0.3237311588831233, 0.4510798122065728, 0.5800000000000001],
    '11316965': [0.41953871788125935, 0.5233710427080593, 0.5394858495884542, 0.5686122699540221, 0.44457849438117786, 0.41014645268788913, 0.2876085240726125, 0.32105836809862065, 0.3410631287505794, 0.5599716866488769, 0.4356497663522131, 0.38524072612470406, 0.2547186830533318, 0.5193470389997621, 0.5008168276518711, 0.503713308527831, 0.5233459866451184, 0.7144197642224478, 0.4846707006928001, 0.6290512521767455, 0.43589155735959206, 0.48750328860826103, 0.5208178298943886, 0.46971974793600685, 0.4245749865323662, 0.4899437491386978, 0.5784317410205334, 0.5879718369852545, 0.5613560341263577, 0.5330351661843374, 0.5557071447363475, 0.6610077548514802, 0.432626752358402, 0.35055311258941885, 0.4077949411808922, 0.450677140100976, 0.7402437954924143, 0.3208842284611819, 0.5578895278184939, 0.4294809636561807, 0.6333759286403328, 0.558529710226632, 0.7364427907442903, 0.5084388819984715, 0.6593728467445911, 0.5432580398641962, 0.7180441237268387, 0.5499580310945741, 0.5266859598351311, 0.4294784580498866, 0.7363513361145564, 0.38293180992470655, 0.48612520514651536, 0.4070156976234324, 0.48788539356810867, 0.7043985918492626, 0.44388569424086394, 0.5604051565377532, 0.31743025018478843, 0.7034527254732463], 
    '11316966': [0.692544568471956, 0.5206812743513611, 0.4311709951015398, 0.5075280941105724, 0.27109407298831134, 0.703259793788602, 0.4183397852695406, 0.44258528457423485, 0.48983851367434633, 0.44801493341351273, 0.4896844188872603, 0.5151576652760552, 0.5450996604903472, 0.37892659826361486, 0.4875408727026722, 0.44566467470966287, 0.4980005261773217, 0.48848924468498267, 0.4950576915849213, 0.49146339935605915, 0.5690933463624861, 0.570931208579196, 0.6871675373648538, 0.374402726099648, 0.5058768995627717, 0.4743964620839128, 0.3695355858733917, 0.28367848060034323, 0.39870961275854727, 0.6929028701720099, 0.6385249495746733, 0.4937710627529096, 0.6773505719046367, 0.48232294759524436, 0.4220568522068127, 0.5065759637188209, 0.3001240275115571, 0.5050663359266359, 0.5209355933902107, 0.43913506470728253, 0.4660816075969983, 0.3218050387742574, 0.42874055699627917, 0.7188860074416507, 0.43912253667581214, 0.4126959070921187, 0.45577855451572896, 0.5432455118327257, 0.45458713872289247, 0.40945239974442815, 0.40407536863732596, 0.5207238696583606, 0.5276055173450597, 0.4790431089562897, 0.509386001177635, 0.4626376517457812, 0.46803598050638306, 0.4510855539269114, 0.5035792585910976, 0.4673394219566279], 
    '11316967': [0.5025093647035241, 0.44322296137607897, 0.5101978176169178, 0.4907204870898636, 0.49208980092958, 0.4115708898660754, 0.49282269077059926, 0.49445384046804725, 0.7102704801994463, 0.4550093333834454, 0.6303904987409328, 0.31808296062439706, 0.5858784029265482, 0.5136455318775761, 0.3903859886496035, 0.5291402012001855, 0.5227195850715978, 0.5484396336803599, 0.6941494093033161, 0.5409491236641987, 0.4715676325778931, 0.49954272685132983, 0.5232921161097958, 0.542015259142331, 0.5227446411345387, 0.4437829643828066, 0.5114142894726952, 0.5760714598915073, 0.5037371117876248, 0.5231994086769146, 0.5089851041705817, 0.6064243745380288, 0.4904223199408677, 0.43487803961363547, 0.48239310457147866, 0.5226444168827752, 0.4782901742649178, 0.6532002856391175, 0.5324526127209631, 0.5091091316821388, 0.5825284073113591, 0.36602147304594024, 0.6456621691033688, 0.5204595281943348, 0.462389596722667, 0.336703373798875, 0.5722942584031772, 0.4481314441061876, 0.3600017539244058, 0.5294696884278574, 0.49597599629170264, 0.7102303904987409, 0.6212462885706769, 0.48966687964320166, 0.4575374901341752, 0.54195637739442, 0.7395848210370706, 0.43537039125042276, 0.5094949950514276, 0.5301975670562885], 
}


auc_scores_lstm_ocsvm_digits_01 = {'22_09_06_1613': [0.9892361111111111, 0.9918055555555556, 0.9877777777777778, 0.9727083333333333, 0.9630555555555554, 0.9824305555555556, 0.7838888888888889, 0.9756249999999999, 0.9944444444444445, 0.18576388888888887]}
auc_scores_lstm_ocsvm_digits_05 = {'22_09_05_1618': [0.8865972222222221, 0.04118055555555556, 0.9443750000000001, 0.6231944444444445, 0.6321527777777778, 0.7145833333333332, 0.20152777777777775, 0.04541666666666667, 0.9493750000000001, 0.4759027777777778], }

# For QG
dicts = [auc_scores_lstm_ocsvm_hypertraining, auc_scores_lstm_ocsvm, auc_scores_lstm, auc_scores_hand]
labels = ["LSTM + OCSVM - HyperTraining", "LSTM + OCSVM - RegularTraining", "Hand Cut LSTM Hidden State", "Hand Cut Variables"]

# for digits -> comment if want to use qg
# dicts = [auc_scores_lstm_ocsvm_digits_01, auc_scores_lstm_ocsvm_digits_05]
# labels = [r"$\nu = 0.1$", r"$\nu = 0.5$"]


# store for best job/trials
best_dict = {}

# set font size & kwargs
plt.rcParams.update({'font.size': 13.5})
kwargs = dict(histtype='stepfilled', density=True, alpha=0.5,  bins=40) # normed=True,

# make plots and print best scores
print("Best AUC Scores:")
fig, ax = plt.subplots(figsize=[6 * 1.36, 6], dpi=160)
kwargs = dict(ax=ax, kde=False, element="step",bins=60)
for i, (d, l) in enumerate(zip(dicts,labels)):
    sns.histplot(np.concatenate(list(d.values())).ravel(), color=sns.color_palette()[i] ,label=l, **kwargs)
    max_auc = 0
    job = 0
    trial = 0
    dim = -1
    for j, x in d.items():
        try:    
            max_auc, trial, job = (max(x), x.index(max(x)), j) if max(x) > max_auc else (max_auc, trial, job)
        except TypeError: # in case of hidden dimensions
            max_auc = max([y for z in x for y in z])
            for k, hidden in enumerate(x):
                if max_auc in hidden:
                    dim = hidden.index(max_auc)
                    trial = k
                    job = j
    print(f"For {l}:\nJob {job}{' - Trial '+str(trial) if len(x)>1 else ''}{' - Dimension '+str(dim) if dim>=0 else ''}\nAUC {max_auc}\n") 
    best_dict[job] = trial if dim < 0 else (trial, dim)
plt.xlabel("Area Under Curve")
plt.legend(loc=2)

# store roc curve plots in designated directory
out_dir = f"output/ROC_curves_best"
try:
    os.mkdir(out_dir)
except FileExistsError:
    pass

out_file = out_dir + "/auc_scores_" + time.strftime("%y_%m_%d_%H%M")

# save plot without title
plt.savefig(out_file+"_no_title")

# save plot with title
plt.title("AUC Scores For Various Tests", y=1.04)
plt.savefig(out_file)

print("Best dict:\n",best_dict)

"""
plt.figure()
kwargs = dict(multiple="stack", kde=False, element="step",bins=60)
sns.histplot(pd.DataFrame(dict(zip(labels, dicts))).melt(), hue="variable", x="value")#,  **kwargs)
plt.show()
"""
