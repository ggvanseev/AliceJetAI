Number of jets in dataset:		21477
Applying cuts: -2 < eta < 2 and jet_pt > 130 GeV
	jets left after cuts:	4373
Splitting data complete
  0%|          | 0/4 [00:00<?, ?trial/s, best loss=?]                                                     
Device: cuda

Hyper Parameters:
  batch_size	  300
  dropout   	  0
  hidden_dim	  9
  learning_rate	  3.1622776601683795e-05
  min_epochs	  100
  num_layers	  1
  output_dim	  1
  pooling   	  mean
  scaler_id 	  minmax
  svm_gamma 	  auto
  svm_nu    	  0.1
  variables 	  ('sigJetRecur_dr12', 'sigJetRecur_jetpt', 'sigJetRecur_z')
Nr. of train batches: 45, out of max.: 45
Nr. of validation batches: 12, out of max.: 12
Branch filler done in: 0.42355942726135254
Dataprep done in: 0.44739603996276855
Training done in: 65.2570116519928
  Model done learning in 167 epochs
  With cost condition: 3.4534962593471858e-09, vs epsilon: 1e-08 
  With loss: 9.2482E-03
Passed in: 00:01:07
  0%|          | 0/4 [01:07<?, ?trial/s, best loss=?] 25%|██▌       | 1/4 [01:07<03:23, 67.73s/trial, best loss: 0.00924819469072033]                                                                                
Device: cuda

Hyper Parameters:
  batch_size	  300
  dropout   	  0
  hidden_dim	  9
  learning_rate	  3.1622776601683795e-05
  min_epochs	  100
  num_layers	  1
  output_dim	  1
  pooling   	  mean
  scaler_id 	  minmax
  svm_gamma 	  auto
  svm_nu    	  0.1
  variables 	  ('sigJetRecur_dr12', 'sigJetRecur_jetpt', 'sigJetRecur_z')
Nr. of train batches: 45, out of max.: 45
Nr. of validation batches: 12, out of max.: 12
Branch filler done in: 0.42510485649108887
Dataprep done in: 0.4489250183105469
Training done in: 61.55391550064087
  Model done learning in 155 epochs
  With cost condition: 1.94573410895608e-09, vs epsilon: 1e-08 
Training done in: 42.18298697471619
  Model done learning in 105 epochs
  With cost condition: 3.674254982075257e-09, vs epsilon: 1e-08 
Training done in: 358.0685770511627
  Algorithm failed: not done learning in max = 900 epochs
  With cost condition: 0.00011842281997780019, vs epsilon: 1e-08 
Training done in: 120.81692695617676
  Model done learning in 298 epochs
  With cost condition: 8.085686744875356e-10, vs epsilon: 1e-08 
Failed in: 00:09:44
 25%|██▌       | 1/4 [10:51<03:23, 67.73s/trial, best loss: 0.00924819469072033] 50%|█████     | 2/4 [10:51<12:22, 371.49s/trial, best loss: 0.00924819469072033]                                                                                 
Device: cuda

Hyper Parameters:
  batch_size	  300
  dropout   	  0
  hidden_dim	  9
  learning_rate	  3.1622776601683795e-05
  min_epochs	  100
  num_layers	  1
  output_dim	  1
  pooling   	  mean
  scaler_id 	  minmax
  svm_gamma 	  auto
  svm_nu    	  0.1
  variables 	  ('sigJetRecur_dr12', 'sigJetRecur_jetpt', 'sigJetRecur_z')
Nr. of train batches: 45, out of max.: 45
Nr. of validation batches: 12, out of max.: 12
Branch filler done in: 0.3564748764038086
Dataprep done in: 0.38007187843322754
Training done in: 367.206871509552
  Algorithm failed: not done learning in max = 900 epochs
  With cost condition: 3.0335813369853e-06, vs epsilon: 1e-08 
Training done in: 363.5206735134125
  Algorithm failed: not done learning in max = 900 epochs
  With cost condition: 2.7075192095274733e-08, vs epsilon: 1e-08 
Training done in: 358.7716472148895
  Algorithm failed: not done learning in max = 900 epochs
  With cost condition: 2.992190640188139e-08, vs epsilon: 1e-08 
Training done in: 363.66206765174866
  Algorithm failed: not done learning in max = 900 epochs
  With cost condition: 1.8340780808484528e-06, vs epsilon: 1e-08 
Failed in: 00:24:13
 50%|█████     | 2/4 [35:05<12:22, 371.49s/trial, best loss: 0.00924819469072033] 75%|███████▌  | 3/4 [35:05<14:25, 865.62s/trial, best loss: 0.00924819469072033]                                                                                 
Device: cuda

Hyper Parameters:
  batch_size	  300
  dropout   	  0
  hidden_dim	  9
  learning_rate	  3.1622776601683795e-05
  min_epochs	  100
  num_layers	  1
  output_dim	  1
  pooling   	  mean
  scaler_id 	  minmax
  svm_gamma 	  auto
  svm_nu    	  0.1
  variables 	  ('sigJetRecur_dr12', 'sigJetRecur_jetpt', 'sigJetRecur_z')
Nr. of train batches: 45, out of max.: 45
Nr. of validation batches: 12, out of max.: 12
Branch filler done in: 0.35741686820983887
Dataprep done in: 0.38106584548950195
Training done in: 55.06167960166931
  Model done learning in 134 epochs
  With cost condition: 2.0966824166693163e-10, vs epsilon: 1e-08 
Training done in: 45.714237689971924
  Model done learning in 111 epochs
  With cost condition: 1.5826957021419026e-10, vs epsilon: 1e-08 
  With loss: 3.7761E-03
Passed in: 00:01:41
 75%|███████▌  | 3/4 [36:47<14:25, 865.62s/trial, best loss: 0.00924819469072033]100%|██████████| 4/4 [36:47<00:00, 564.09s/trial, best loss: 0.0037760517050857006]100%|██████████| 4/4 [36:47<00:00, 551.84s/trial, best loss: 0.0037760517050857006]

Best Hyper Parameters:

Model 0 from trial 3:
  batch_size  	  300
  dropout     	  0
  hidden_dim  	  9
  learning_rate	  3.1622776601683795e-05
  min_epochs  	  100
  num_layers  	  1
  output_dim  	  1
  pooling     	  mean
  scaler_id   	  minmax
  svm_gamma   	  auto
  svm_nu      	  0.1
  variables   	  ('sigJetRecur_dr12', 'sigJetRecur_jetpt', 'sigJetRecur_z')
with loss: 		0.0037760517050857006
with final cost:	0.00321549894382928

Regular training completed on dataset:
	samples/JetToyHIResultSoftDropSkinny.root
Stored results in:
	storing_results/trials_test_10214090.p
Plotting complete, stored results at:
	output/cost_condition_10214090/
	output/violin_plots_10214090/

Completed run in: 2208.11 seconds
	on job: 10214090
