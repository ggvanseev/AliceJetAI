Number of jets in dataset:		21477
Number of gluon jets in dataset:	3252
Number of quark jets in dataset:	2885
Applying cuts: -2 < eta < 2 and jet_pt > 130 GeV
	gluon jets left after cuts:	1537
	quark jets left after cuts:	1475 
Loading data complete
Splitting data complete
  0%|          | 0/4 [00:00<?, ?trial/s, best loss=?]                                                     
Device: cuda

Hyper Parameters:
  batch_size	  500
  dropout   	  0
  hidden_dim	  20
  learning_rate	  0.0001
  min_epochs	  100
  num_layers	  1
  output_dim	  1
  pooling   	  last
  scaler_id 	  minmax
  svm_gamma 	  scale
  svm_nu    	  0.1
  variables 	  ('sigJetRecur_dr12', 'sigJetRecur_jetpt', 'sigJetRecur_z')
Nr. of train batches: 14, out of max.: 14
Nr. of validation batches: 2, out of max.: 2
Branch filler done in: 0.16391253471374512
Dataprep done in: 0.20096492767333984
Training done in: 95.34983515739441
  Algorithm failed: not done learning in max = 800 epochs
  With cost condition: 1.777172703824725e-05, vs epsilon: 1e-08 
Training done in: 97.54545783996582
  Algorithm failed: not done learning in max = 800 epochs
  With cost condition: 1.8620396669195288e-05, vs epsilon: 1e-08 
Training done in: 99.35356426239014
  Algorithm failed: not done learning in max = 800 epochs
  With cost condition: 2.553033941605904e-08, vs epsilon: 1e-08 
Training done in: 59.10298776626587
  Model done learning in 468 epochs
  With cost condition: 1.481462351291474e-09, vs epsilon: 1e-08 
Failed in: 00:05:57
  0%|          | 0/4 [05:57<?, ?trial/s, best loss=?] 25%|██▌       | 1/4 [05:57<17:52, 357.61s/trial, best loss: 0.40623118297757177]                                                                                 
Device: cuda

Hyper Parameters:
  batch_size	  500
  dropout   	  0
  hidden_dim	  20
  learning_rate	  0.0001
  min_epochs	  100
  num_layers	  1
  output_dim	  1
  pooling   	  last
  scaler_id 	  minmax
  svm_gamma 	  scale
  svm_nu    	  0.1
  variables 	  ('sigJetRecur_dr12', 'sigJetRecur_jetpt', 'sigJetRecur_z')
Nr. of train batches: 14, out of max.: 14
Nr. of validation batches: 2, out of max.: 2
Branch filler done in: 0.16404199600219727
Dataprep done in: 0.17481350898742676
Training done in: 102.47533679008484
  Algorithm failed: not done learning in max = 800 epochs
  With cost condition: 6.219944042724856e-05, vs epsilon: 1e-08 
Training done in: 103.61807608604431
  Algorithm failed: not done learning in max = 800 epochs
  With cost condition: 2.976669086247399e-05, vs epsilon: 1e-08 
Training done in: 104.83965063095093
  Algorithm failed: not done learning in max = 800 epochs
  With cost condition: 3.931651081693034e-06, vs epsilon: 1e-08 
Training done in: 105.72032809257507
  Algorithm failed: not done learning in max = 800 epochs
  With cost condition: 2.4055410482474294e-07, vs epsilon: 1e-08 
Failed in: 00:06:56
 25%|██▌       | 1/4 [12:54<17:52, 357.61s/trial, best loss: 0.40623118297757177] 50%|█████     | 2/4 [12:54<13:04, 392.45s/trial, best loss: 0.40623118297757177]                                                                                 
Device: cuda

Hyper Parameters:
  batch_size	  500
  dropout   	  0
  hidden_dim	  20
  learning_rate	  0.0001
  min_epochs	  100
  num_layers	  1
  output_dim	  1
  pooling   	  last
  scaler_id 	  minmax
  svm_gamma 	  scale
  svm_nu    	  0.1
  variables 	  ('sigJetRecur_dr12', 'sigJetRecur_jetpt', 'sigJetRecur_z')
Nr. of train batches: 14, out of max.: 14
Nr. of validation batches: 2, out of max.: 2
Branch filler done in: 0.1664261817932129
Dataprep done in: 0.17723512649536133
Training done in: 106.17360281944275
  Algorithm failed: not done learning in max = 800 epochs
  With cost condition: 6.482569254938731e-06, vs epsilon: 1e-08 
Training done in: 106.47502756118774
  Algorithm failed: not done learning in max = 800 epochs
  With cost condition: 1.0691323281244668e-05, vs epsilon: 1e-08 
Training done in: 106.99775624275208
  Algorithm failed: not done learning in max = 800 epochs
  With cost condition: 3.3699926715372626e-07, vs epsilon: 1e-08 
Training done in: 107.45129561424255
  Algorithm failed: not done learning in max = 800 epochs
  With cost condition: 1.0606017723574764e-05, vs epsilon: 1e-08 
Failed in: 00:07:07
 50%|█████     | 2/4 [20:01<13:04, 392.45s/trial, best loss: 0.40623118297757177] 75%|███████▌  | 3/4 [20:01<06:48, 408.36s/trial, best loss: 0.40623118297757177]                                                                                 
Device: cuda

Hyper Parameters:
  batch_size	  500
  dropout   	  0
  hidden_dim	  20
  learning_rate	  0.0001
  min_epochs	  100
  num_layers	  1
  output_dim	  1
  pooling   	  last
  scaler_id 	  minmax
  svm_gamma 	  scale
  svm_nu    	  0.1
  variables 	  ('sigJetRecur_dr12', 'sigJetRecur_jetpt', 'sigJetRecur_z')
Nr. of train batches: 14, out of max.: 14
Nr. of validation batches: 2, out of max.: 2
Branch filler done in: 0.16583490371704102
Dataprep done in: 0.17661404609680176
Training done in: 107.68700742721558
  Algorithm failed: not done learning in max = 800 epochs
  With cost condition: 4.520586123661745e-06, vs epsilon: 1e-08 
Training done in: 108.3430438041687
  Algorithm failed: not done learning in max = 800 epochs
  With cost condition: 9.865884365926342e-06, vs epsilon: 1e-08 
Training done in: 108.50852537155151
  Algorithm failed: not done learning in max = 800 epochs
  With cost condition: 5.0557033980765e-07, vs epsilon: 1e-08 
Training done in: 108.6212830543518
  Algorithm failed: not done learning in max = 800 epochs
  With cost condition: 2.426993497915887e-06, vs epsilon: 1e-08 
Failed in: 00:07:13
 75%|███████▌  | 3/4 [27:15<06:48, 408.36s/trial, best loss: 0.40623118297757177]100%|██████████| 4/4 [27:15<00:00, 418.22s/trial, best loss: 0.40623118297757177]100%|██████████| 4/4 [27:15<00:00, 408.77s/trial, best loss: 0.40623118297757177]

Best Hyper Parameters:

Model 0 from trial 0:
  batch_size  	  500
  dropout     	  0
  hidden_dim  	  20
  learning_rate	  0.0001
  min_epochs  	  100
  num_layers  	  1
  output_dim  	  1
  pooling     	  last
  scaler_id   	  minmax
  svm_gamma   	  scale
  svm_nu      	  0.1
  variables   	  ('sigJetRecur_dr12', 'sigJetRecur_jetpt', 'sigJetRecur_z')
with loss: 		0.40623118297757177
with final cost:	0.010111457275531211

Regular training completed on dataset:
	samples/JetToyHIResultSoftDropSkinny.root
Stored results in:
	storing_results/trials_test_10214086.p
Plotting complete, stored results at:
	output/cost_condition_10214086/
	output/violin_plots_10214086/

Completed run in: 1635.91 seconds
	on job: 10214086
